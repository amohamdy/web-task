{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf-learn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/amohamdy/web-task/blob/master/tf_learn.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "wL0l0-NsPjMm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "0bee4216-828c-48a0-e864-6f01c43c73da"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TE0ZJwsfhTZy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Make Current Directory**"
      ]
    },
    {
      "metadata": {
        "id": "D9VDHc4NPn-8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"drive/My Drive/sentiment-model/tf-learn\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-vTlA3_8P74i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f1799383-b0b9-42ad-94fd-eda2e537fb5a"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf-learn.ipynb\ttweets-pos-neg.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z9qu_6RkfMsS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Download and unzip ngrok**"
      ]
    },
    {
      "metadata": {
        "id": "gVkK9ODWhgq7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "f6d0802f-7554-4176-e907-8553f2ba6eb3"
      },
      "cell_type": "code",
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Redirecting output to ‘wget-log’.\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6L7UXJXoiNcB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Run Tensor Board**"
      ]
    },
    {
      "metadata": {
        "id": "GnD7oFmGiMTD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LOG_DIR = './log'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gsOBNhsaiTTw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Run ngrok**"
      ]
    },
    {
      "metadata": {
        "id": "p6ZIEPJNiXdn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jBl5B-m2iayj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Get URL**\n",
        "Run the next cell to start the training before open the url."
      ]
    },
    {
      "metadata": {
        "id": "_R9yPASFih85",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "00fe4ba4-d81d-4134-c160-21237db99d75"
      },
      "cell_type": "code",
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://33b28690.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ETa-I57RT63w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "be97eb3f-20db-44e7-b66a-005ad139138d"
      },
      "cell_type": "code",
      "source": [
        "!pip install tflearn"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tflearn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/ec/e9ce1b52e71f6dff3bd944f020cef7140779e783ab27512ea7c7275ddee5/tflearn-0.3.2.tar.gz (98kB)\n",
            "\u001b[K    100% |████████████████████████████████| 102kB 6.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tflearn) (1.14.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tflearn) (1.11.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from tflearn) (4.0.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->tflearn) (0.46)\n",
            "Building wheels for collected packages: tflearn\n",
            "  Running setup.py bdist_wheel for tflearn ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/d0/f6/69/0ef3ee395aac2e5d15d89efd29a9a216f3c27767b43b72c006\n",
            "Successfully built tflearn\n",
            "Installing collected packages: tflearn\n",
            "Successfully installed tflearn-0.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wcz9o47PjTXt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d03b924e-c337-46ed-ecd8-a87467e45ca6"
      },
      "cell_type": "code",
      "source": [
        "import os   # iterate throw DIRECTORIES \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import set_random_seed\n",
        "tf.set_random_seed(7)\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tflearn\n",
        "from tflearn.data_utils import to_categorical, pad_sequences\n",
        "from tflearn.layers.core import input_data, dropout, fully_connected, flatten\n",
        "from tflearn.layers.conv import conv_1d,max_pool_1d\n",
        "from tflearn.layers.estimator import regression\n",
        "import re\n",
        "import string\n",
        "import collections\n",
        "import time\n",
        "from sklearn.utils.multiclass import type_of_target"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "gDGI8sjxhoXp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Load CSV File**"
      ]
    },
    {
      "metadata": {
        "id": "UKzQiFm4QPhY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Read CSV Files \n",
        "df=pd.read_csv('tweets-pos-neg.csv', usecols = ['text','airline_sentiment'])\n",
        "df = df.reindex(['text','airline_sentiment'], axis=1) #reorder columns\n",
        "df=df.apply(lambda x: x.astype(str).str.lower()) #convert data to lower case"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fIdcHDrBng5p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Normalization Process**"
      ]
    },
    {
      "metadata": {
        "id": "u9m69Fq0QUv-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def normalize(text):\n",
        "    text= re.sub(r\"http\\S+\", r'', text) #replaces links with \"URL\" or space\n",
        "    text= re.sub(r\"@\\S+\", r'', text) #replaces @Mention with \"mention\" or space\n",
        "    punctuation = re.compile(r'[!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~|0-9]')\n",
        "    text = re.sub(punctuation, ' ', text)\n",
        "    text= re.sub(r'(.)\\1\\1+', r'\\1', text)  #solve el.ongation problem ex loooool=>lol, lool=>lool  \n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qD2rWECOQmMf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def prepareDataSets(df):\n",
        "    sentences=[]\n",
        "    for index, r in df.iterrows():\n",
        "        text= normalize(r['text'])\n",
        "#         if r['airline_sentiment']=='positive':\n",
        "#             sentences.append([text,1])\n",
        "#         else:\n",
        "#             sentences.append([text,0])\n",
        "#         #text= stopWordRemove(text)\n",
        "        sentences.append([text,r['airline_sentiment']])\n",
        "        df_sentences=pd.DataFrame(sentences,columns=['text','airline_sentiment'])\n",
        "    return df_sentences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4nfpS1GoQpJF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "edit_df=prepareDataSets(df)\n",
        "edit_df=shuffle(edit_df)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LXRRotTiQsYm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X=edit_df.iloc[:,0]\n",
        "Y=edit_df.iloc[:,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y9dbOXcvnmoE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "** Convert reviews to Tokens then Tokens to Integers**"
      ]
    },
    {
      "metadata": {
        "id": "8SiXFVhhQw0f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "max_features = 50000\n",
        "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
        "tokenizer.fit_on_texts(X.values)\n",
        "#convert review tokens to integers\n",
        "X_seq = tokenizer.texts_to_sequences(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Prl6OWZOQ5hy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7271ff97-35bd-4ffb-fdb9-070bbc07a984"
      },
      "cell_type": "code",
      "source": [
        "print('Fitted tokenizer on {} documents'.format(tokenizer.document_count))\n",
        "print('{} words in dictionary'.format(tokenizer.num_words))\n",
        "print('Top 5 most common words are:', collections.Counter(tokenizer.word_counts).most_common(5))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitted tokenizer on 11541 documents\n",
            "50000 words in dictionary\n",
            "Top 5 most common words are: [('to', 6988), ('the', 5085), ('i', 4235), ('a', 3763), ('you', 3403)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1c4OqkBgcX12",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Get The Length of each Review then get MAX **"
      ]
    },
    {
      "metadata": {
        "id": "phI3mjHGcV9W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def countWords(review):\n",
        "    counts=[]\n",
        "    for review in X:\n",
        "        review_legnth=len(review.split())\n",
        "        counts.append(review_legnth)\n",
        "    return counts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vHNyU_zAclhc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c18e167f-1f30-4f8d-bcf5-0be970ec40ed"
      },
      "cell_type": "code",
      "source": [
        "counts=countWords(X)\n",
        "max(counts)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "_OS4PbxgQ9kA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Equal Length of Sequence Padding Sequence according to MAX length of reviews\n",
        "seq_len=35\n",
        "X_pad = pad_sequences(X_seq,maxlen=seq_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "06ztBaXbRAv5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Encoding Target Value\n",
        "# convert target value from string to integer\n",
        "le=LabelEncoder()\n",
        "Y_le=le.fit_transform(Y)\n",
        "Y_le_oh=to_categorical(Y_le, nb_classes=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PWGs91UPRQex",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "39042cbf-f103-42fa-8ee9-63ae8ff85a81"
      },
      "cell_type": "code",
      "source": [
        "Y_le_oh\n",
        "print(type_of_target(Y_le_oh))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "multilabel-indicator\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9JvaKXkJkVar",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Train, Test split**"
      ]
    },
    {
      "metadata": {
        "id": "hctvEHs6RXsA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "ae8d1974-b4c5-4617-8aa4-d808feed8b73"
      },
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X_pad,Y_le_oh, test_size = 0.33, random_state = 42)\n",
        "X_train, X_Val, Y_train, Y_Val = train_test_split(X_train,Y_train, test_size = 0.1, random_state = 42)\n",
        "print(X_train.shape,Y_train.shape)\n",
        "print(X_test.shape,Y_test.shape)\n",
        "print(X_Val.shape,Y_Val.shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6958, 35) (6958, 2)\n",
            "(3809, 35) (3809, 2)\n",
            "(774, 35) (774, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hoVp-ypRRibl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "tf.reset_default_graph()     #solve problem list out of index\n",
        "net =input_data(shape=[None, 35], name='input')   \n",
        "net=tflearn.embedding(net, max_features, output_dim=32)\n",
        "conv1=conv_1d(net, 100, 3, padding='same', activation='relu')\n",
        "conv1=max_pool_1d(conv1,2)\n",
        "conv1=flatten(conv1)\n",
        "conv1=fully_connected(conv1, 256, activation='relu')\n",
        "conv1=fully_connected(conv1, 2, activation='softmax')\n",
        "conv1 = regression(conv1, optimizer='adam', learning_rate=0.001,\n",
        "                     loss='categorical_crossentropy', name='target')\n",
        "Name=\"tflearn-{}\".format(int(time.time()))\n",
        "model = tflearn.DNN(conv1, tensorboard_verbose=3, tensorboard_dir='./log/{}'.format(Name))\n",
        "\n",
        "#print(conv1.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z3Vnj7dbjBy0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Name=\"Sentimnt-Analysis-tflearn-{}\".format(int(time.time()))\n",
        "#tensorboard = TensorBoard(log_dir='./log/{}'.format(Name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VP6EBMIZRnzY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "50c0c6b8-0779-4f97-c094-fb00011715cf"
      },
      "cell_type": "code",
      "source": [
        "history=model.fit(X_train, Y_train, n_epoch=3, validation_set=(X_Val, Y_Val),show_metric=True, batch_size=32)\n",
        "scores = model.evaluate(X_test, Y_test)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[-1]*100))"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Step: 653  | total loss: \u001b[1m\u001b[32m0.04374\u001b[0m\u001b[0m | time: 31.976s\n",
            "| Adam | epoch: 003 | loss: 0.04374 - acc: 0.9904 -- iter: 6944/6958\n",
            "Training Step: 654  | total loss: \u001b[1m\u001b[32m0.04392\u001b[0m\u001b[0m | time: 33.139s\n",
            "| Adam | epoch: 003 | loss: 0.04392 - acc: 0.9913 | val_loss: 0.21007 - val_acc: 0.9315 -- iter: 6958/6958\n",
            "--\n",
            "Accuracy: 91.60%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lkpKF-DORqoj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def tflearn_evaluate(): \n",
        "    # predict class with test set\n",
        "    Y_predict =model.predict_label(X_test)\n",
        "    #Y_predict=tf.nn.softmax(Y_predict)\n",
        "    print('Accuracy:\\t{:0.1f}%'.format(accuracy_score(tf.argmax(Y_test, axis=1),Y_predict)*100))\n",
        "    \n",
        "    #classification report\n",
        "    print('\\n')\n",
        "    print(classification_report(Y_test, Y_predict))\n",
        "    #confusion matrix\n",
        "    confmat = tf.confusion_matrix(Y_test, Y_predict,num_classes=None,dtype=tf.int32,name=None,weights=None)\n",
        "\n",
        "#     fig, ax = plt.subplots(figsize=(4, 4))\n",
        "#     ax.matshow(confmat, cmap=plt.cm.Blues, alpha=0.3)\n",
        "#     for i in range(confmat.shape[0]):\n",
        "#         for j in range(confmat.shape[1]):\n",
        "#             ax.text(x=j, y=i, s=confmat[i, j], va='center', ha='center')\n",
        "#     plt.xlabel('Predicted label')\n",
        "#     plt.ylabel('True label')\n",
        "#     plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4iEWBr1A8CJB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "outputId": "8775d9ed-7218-4486-f2c2-fb627d52af42"
      },
      "cell_type": "code",
      "source": [
        "tflearn_evaluate()"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-a6015b28c8cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtflearn_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-80-f9853d5d2378>\u001b[0m in \u001b[0;36mtflearn_evaluate\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mY_predict\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#Y_predict=tf.nn.softmax(Y_predict)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy:\\t{:0.1f}%'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#classification report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mdiffering_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \"\"\"\n\u001b[1;32m     71\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         raise ValueError('Expected array-like (array or non-string sequence), '\n\u001b[0;32m--> 243\u001b[0;31m                          'got %r' % y)\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0msparseseries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'SparseSeries'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected array-like (array or non-string sequence), got <tf.Tensor 'ArgMax_31:0' shape=(3809,) dtype=int64>"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "pTfHylXK-flP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Y_predict =model.predict(X_test)\n",
        "Y_predict=tf.nn.softmax(Y_predict)\n",
        "b=tf.equal(tf.argmax(Y_test,axis=None),tf.argmax(Y_predict,axis=None))\n",
        "\n",
        "accuracy=tf.reduce_mean(tf.cast(b,'float'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "18IOs-wCjU2v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "27da9736-083c-47a4-cf15-e15ab38407d1"
      },
      "cell_type": "code",
      "source": [
        "accuracy"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'Mean_1:0' shape=() dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "metadata": {
        "id": "G0rX7ui4nisE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}